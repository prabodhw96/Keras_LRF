{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "from learningratefinder import LearningRateFinder\n",
    "from minigooglenet import MiniGoogLeNet\n",
    "from clr_callback import CyclicLR\n",
    "import config\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST data...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading Fashion MNIST data...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "\n",
    "# Fashion MNIST images are 28x28 but the network we will be training expects 32x32 images\n",
    "trainX = np.array([cv2.resize(x, (32, 32)) for x in trainX])\n",
    "testX = np.array([cv2.resize(x, (32, 32)) for x in testX])\n",
    "\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "trainX = trainX.astype(\"float\")/255.0\n",
    "testY = testY.astype(\"float\")/255.0\n",
    "\n",
    "# reshape the data matrices to include channel dimension (required for training)\n",
    "trainX = trainX.reshape((trainX.shape[0], 32, 32, 1))\n",
    "testX = testX.reshape((testX.shape[0], 32, 32, 1))\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                      height_shift_range=0.1,\n",
    "                                      horizontal_flip=True,\n",
    "                                      fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=config.MIN_LR, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width=32, height=32, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] finding learning rate...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'numSamples' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3a7409cdf7fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m          \u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e+1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m          \u001b[0mstepsPerEpoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m          batchSize=config.BATCH_SIZE)\n\u001b[0m",
      "\u001b[1;32mD:\\CSE\\GitHub\\Keras LR Finder\\learningratefinder.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(self, trainData, startLR, endLR, epochs, stepsPerEpoch, batchSize, sampleSize, verbose)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# compute the training epochs based on a default sample size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumSamples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# Compute the total number of batch updates that will take place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'numSamples' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] finding learning rate...\")\n",
    "lrf = LearningRateFinder(model)\n",
    "lrf.find(aug.flow(trainX, trainY, batch_size=config.BATCH_SIZE),\n",
    "         1e-10, 1e+1,\n",
    "         stepsPerEpoch=np.ceil((len(trainX) / float(config.BATCH_SIZE))),\n",
    "         batchSize=config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
